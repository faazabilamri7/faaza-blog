---
title: '---'
category: general
tags:
  - general
  - auto-post
description: "publishDate: 2025-10-09T00:00:00Z\ntitle: 'Deploying Kubernetes to the Cloud: Civo and Google Kubernetes Engine Guide'\nexcerpt: 'Ready to take your K..."
pubDate: '2025-10-09T03:45:06.777Z'
draft: false
excerpt: "publishDate: 2025-10-09T00:00:00Z\ntitle: 'Deploying Kubernetes to the Cloud: Civo and Google Kubernetes Engine Guide'\nexcerpt: 'Ready to take your K..."
---

publishDate: 2025-10-09T00:00:00Z
title: 'Deploying Kubernetes to the Cloud: Civo and Google Kubernetes Engine Guide'
excerpt: 'Ready to take your Kubernetes skills to the cloud? Learn how to deploy managed Kubernetes clusters on Civo and Google Cloud Platform—with step-by-step instructions, cost breakdowns, and real-world networking examples.'
image: '~/assets/images/default.png'
category: DevOps
tags:
  - kubernetes
  - cloud-computing
  - gcp
  - civo
  - devops
  - tutorial
metadata:
  canonical: https://faazabilamri.my.id/deploying-kubernetes-to-cloud
---

## Introduction

You've been practicing with Kubernetes on your laptop using Kind. Everything works great locally. But now you're thinking: "How do I deploy this to the real world? How do I make my application accessible on the internet?"

Welcome to the world of **cloud-hosted Kubernetes clusters!**

Moving from local development to cloud deployment might seem intimidating, but it's actually more straightforward than you think—especially with managed Kubernetes services that handle most of the complexity for you.

In this comprehensive guide, you'll learn:

- The difference between local and cloud Kubernetes clusters
- How to deploy a cluster on **Civo** (fast, affordable, beginner-friendly)
- How to deploy a cluster on **Google Kubernetes Engine** (GKE) (industry-leading, feature-rich)
- How to work with public load balancers and real internet traffic
- How to manage costs and avoid surprise bills
- Best practices for cloud Kubernetes security

By the end, you'll have hands-on experience with two popular managed Kubernetes platforms!

**Source:** This guide is based on the cloud deployment sections from the [Complete Kubernetes Course - From Beginner to Pro](https://www.youtube.com/watch?v=2T86xAtR6Fo&t=2198s) by DevOps Directive (timestamp 36:38 - 51:44).

## Why Move to the Cloud?

You might wonder: "My Kind cluster works fine locally. Why bother with the cloud?"

Great question! Here's why cloud clusters matter:

### What Local Clusters Can't Do

❌ **No public internet access** - Others can't access your applications
❌ **Limited to your hardware** - Can't scale beyond your laptop's resources
❌ **No cloud integrations** - Can't use cloud storage, databases, or other managed services
❌ **Disappears when you shut down** - Not suitable for always-on applications
❌ **Single point of failure** - If your laptop crashes, everything goes down

### What Cloud Clusters Provide

✅ **Public accessibility** - Get real domain names and SSL certificates
✅ **Unlimited scaling** - Add more nodes as needed
✅ **Cloud service integration** - Use managed databases, storage, monitoring
✅ **High availability** - Run across multiple data centers
✅ **Production-ready** - Suitable for real users and real traffic
✅ **Team collaboration** - Multiple people can access the same cluster

**The bottom line:** Local clusters are perfect for learning and development. Cloud clusters are where you deploy real applications.

## Managed vs. Self-Managed Kubernetes

Before we dive into specific providers, let's understand the two approaches:

### Self-Managed Kubernetes

**What it means:** You provision servers and install Kubernetes yourself.

**Analogy:** Like buying land and building a house from scratch—complete control, but you're responsible for everything.

**Responsibilities:**

- Setting up the control plane
- Managing upgrades
- Handling security patches
- Configuring networking
- Managing backups
- Ensuring high availability

**Best for:** Large enterprises with dedicated platform teams, or specific compliance requirements.

### Managed Kubernetes

**What it means:** The cloud provider runs and manages the control plane for you.

**Analogy:** Like renting an apartment—the landlord handles maintenance, you just use the space.

**Provider handles:**

- Control plane management
- Automatic upgrades (usually)
- Security patches
- High availability
- API server access
- Basic monitoring

**You handle:**

- Worker nodes (sometimes)
- Your applications
- Application-level configuration

**Best for:** Most use cases! Faster, easier, less operational overhead.

**Examples:** Google GKE, Amazon EKS, Azure AKS, Civo Kubernetes, DigitalOcean Kubernetes

We'll focus on managed Kubernetes in this guide because it's what 90% of teams use.

## Option 1: Deploying to Civo

Let's start with **Civo**, a cloud provider that specializes in Kubernetes and developer-friendly services.

### Why Civo?

Here's what makes Civo great for learning:

✅ **Super fast provisioning** - Clusters ready in 90-120 seconds (vs. 5-10 minutes on other providers)
✅ **Simple pricing** - Easy to understand costs
✅ **$250 free credit** - For the first month on new accounts
✅ **Optimized for Kubernetes** - It's their specialty
✅ **Great documentation** - Beginner-friendly guides

**Cost estimate:** A basic 2-node cluster costs approximately $20-30/month. With the free credit, you can run it for several weeks at no cost!

### Step 1: Create a Civo Account

1. **Go to [civo.com](https://www.civo.com/)**
2. **Click "Sign Up"** and create an account
3. **Verify your email address**
4. **Complete account verification**

**Important:** Civo has an account verification process for new users to prevent abuse. This might take a few hours or up to a day. Reach out to their support if it takes longer—they're very responsive!

### Step 2: Create an API Key

Once your account is verified:

1. **Log in to Civo dashboard**
2. **Navigate to Settings → Security**
3. **Click "Generate API Key"**
4. **Give it a name** (e.g., "kubernetes-learning")
5. **Copy the API key** - You'll need this in a moment

**Security note:** Treat API keys like passwords! Don't commit them to GitHub or share them publicly.

### Step 3: Configure the Civo CLI

Back in your terminal (with Devbox shell active), authenticate:

```bash
civo apikey add kubernetes-learning YOUR_API_KEY_HERE
```

Replace `YOUR_API_KEY_HERE` with the actual key you copied.

Set it as the current key:

```bash
civo apikey current kubernetes-learning
```

Verify it worked:

```bash
civo apikey list
```

You should see your new key marked as current.

### Step 4: Create a Network

Before creating the cluster, let's create an isolated network (better security practice):

```bash
civo network create devops-directive-kubernetes-course
```

This creates a private network in Civo's New York data center (or whichever region you specified).

**Why a separate network?** Isolation! Your cluster won't share network space with the default network or other resources.

### Step 5: Create a Firewall

Now let's create a firewall to control which traffic can reach our cluster:

```bash
civo firewall create devops-directive-kubernetes-course \
  --network=devops-directive-kubernetes-course \
  --create-rules="true"
```

By default, Civo creates very permissive rules. Let's lock it down to only what we need.

**Delete the default rules:**

```bash
# This script removes the auto-generated permissive rules
for id in $(civo firewall rule list devops-directive-kubernetes-course -o custom -e id); do
  civo firewall rule remove $id --firewall=devops-directive-kubernetes-course
done
```

**Add specific rules we need:**

```bash
# Allow HTTP traffic (port 80)
civo firewall rule create devops-directive-kubernetes-course \
  --start-port=80 --end-port=80 --protocol=tcp --cidr=0.0.0.0/0 --direction=ingress

# Allow HTTPS traffic (port 443)
civo firewall rule create devops-directive-kubernetes-course \
  --start-port=443 --end-port=443 --protocol=tcp --cidr=0.0.0.0/0 --direction=ingress

# Allow Kubernetes API access (port 6443)
civo firewall rule create devops-directive-kubernetes-course \
  --start-port=6443 --end-port=6443 --protocol=tcp --cidr=0.0.0.0/0 --direction=ingress
```

**What these rules mean:**

- **Port 80** - Regular web traffic (HTTP)
- **Port 443** - Encrypted web traffic (HTTPS)
- **Port 6443** - Kubernetes API server access
- **0.0.0.0/0** - Allow from any IP address (whole internet)

**Security consideration:** For production, you'd restrict port 6443 to specific IP addresses (your office, your VPN, etc.). For learning, allowing all IPs is fine.

### Step 6: Create the Cluster!

Now for the main event:

```bash
civo kubernetes create devops-directive-kubernetes-course \
  --nodes=2 \
  --size=g4s.kube.medium \
  --network=devops-directive-kubernetes-course \
  --firewall=devops-directive-kubernetes-course \
  --wait
```

**Let's break down these options:**

- `--nodes=2` - Create 2 worker nodes
- `--size=g4s.kube.medium` - Each node has 2 CPUs, 4GB RAM, 50GB disk
- `--network=...` - Use the network we created
- `--firewall=...` - Use the firewall we created
- `--wait` - Don't return until the cluster is ready

**This takes 90-120 seconds.** Watch the progress in your terminal!

### Step 7: Configure kubectl

Once creation completes, download the cluster configuration:

```bash
civo kubernetes config devops-directive-kubernetes-course --save --switch
```

**What this does:**

- Downloads the cluster credentials
- Adds them to your `~/.kube/config` file
- Switches your context to the new cluster

Verify it worked:

```bash
kubectl get nodes
```

You should see your 2 Civo nodes!

```
NAME                                         STATUS   ROLES    AGE   VERSION
k3s-devops-directive-k-a1b2-abc123           Ready    <none>   2m    v1.27.4
k3s-devops-directive-k-a1b2-def456           Ready    <none>   2m    v1.27.4
```

**Congratulations! You have a cloud Kubernetes cluster running!** 🎉

### Step 8: Explore the Civo Dashboard

Head back to the Civo web dashboard and click on "Kubernetes" in the sidebar.

You'll see:

- Your cluster status
- Number of nodes
- Kubernetes version
- Resource usage
- Costs

Click into your cluster to see:

- Individual node details
- Installed applications
- Cluster configuration
- Access credentials

**Pro tip:** The dashboard is great for getting a quick overview, but you'll do most work via kubectl.

## Option 2: Deploying to Google Kubernetes Engine (GKE)

Now let's deploy to **Google Kubernetes Engine**, Google Cloud's managed Kubernetes service.

### Why GKE?

✅ **Most mature managed Kubernetes** - Google created Kubernetes, after all
✅ **Autopilot mode** - Completely hands-off node management
✅ **Excellent tooling** - Best-in-class monitoring, logging, security
✅ **$300 free credit** - For new accounts (90 days)
✅ **Free tier** - One zonal cluster control plane is always free

**Cost estimate:** A basic 2-node standard cluster costs $50-70/month. Autopilot mode costs less for low-usage workloads. Free credit covers several weeks of learning!

### Step 1: Create a Google Cloud Account

1. **Go to [cloud.google.com](https://cloud.google.com/)**
2. **Click "Get started for free"**
3. **Sign in with a Google account** (or create one)
4. **Enter billing information** - Required even for free tier, but you won't be charged during the free trial
5. **Agree to terms and activate**

**Important:** Google requires a credit card but won't charge you without explicit permission (after free credit runs out).

### Step 2: Create a Project

Google Cloud organizes resources into **projects**. Let's create one:

1. **In the Google Cloud Console, click the project dropdown** (top left)
2. **Click "New Project"**
3. **Name it:** `kubernetes-course`
4. **Click "Create"**

Wait a few seconds for the project to be created, then select it from the project dropdown.

### Step 3: Install and Initialize the gcloud CLI

The `gcloud` command-line tool is already installed via Devbox! We just need to initialize it.

Run:

```bash
gcloud init
```

This interactive setup will:

1. **Ask you to log in** - It'll open a browser window
2. **Choose your account** - Select the Google account you used
3. **Choose your project** - Select `kubernetes-course`
4. **Set default region** - Choose one close to you (e.g., `us-central1`)

**Recommended regions:**

- **US:** `us-central1`, `us-east1`
- **Europe:** `europe-west1`, `europe-west2`
- **Asia:** `asia-southeast1`, `asia-northeast1`

### Step 4: Enable Required APIs

Google Cloud requires you to explicitly enable APIs before using them:

```bash
gcloud services enable \
  compute.googleapis.com \
  container.googleapis.com \
  cloudresourcemanager.googleapis.com \
  iam.googleapis.com \
  secretmanager.googleapis.com \
  servicemanagement.googleapis.com \
  serviceusage.googleapis.com
```

This takes 30-60 seconds. You'll see each API being enabled.

**What these APIs do:**

- **compute** - Virtual machines and networking
- **container** - Kubernetes (GKE)
- **cloudresourcemanager** - Project management
- **iam** - Identity and access management
- **secretmanager** - Secure credential storage
- **servicemanagement/serviceusage** - Managing cloud services

### Step 5: Create a VPC Network

Just like with Civo, let's create an isolated network:

```bash
gcloud compute networks create kubernetes-course \
  --subnet-mode=custom
```

**What's `--subnet-mode=custom`?** This means we'll manually create subnets instead of GCP automatically creating one per region.

### Step 6: Create a Subnet

Now create a subnet within that network:

```bash
gcloud compute networks subnets create subnet-1 \
  --network=kubernetes-course \
  --range=10.0.0.0/24 \
  --region=us-central1
```

**Change the region** to match what you chose during initialization!

**What's `10.0.0.0/24`?** This is the IP address range for the subnet—it provides 256 IP addresses (10.0.0.0 through 10.0.0.255).

### Step 7: Create the GKE Cluster

Time for the main event! Run:

```bash
gcloud container clusters create kubernetes-course \
  --zone=us-central1-a \
  --network=kubernetes-course \
  --subnetwork=subnet-1 \
  --machine-type=e2-standard-2 \
  --num-nodes=2 \
  --enable-ip-alias \
  --gateway-api=standard \
  --workload-pool=kubernetes-course.svc.id.goog
```

**Breakdown of options:**

- `--zone=us-central1-a` - Specific zone (change to match your region)
- `--network/--subnetwork` - Use the network we created
- `--machine-type=e2-standard-2` - 2 CPUs, 8GB RAM per node
- `--num-nodes=2` - Create 2 worker nodes
- `--enable-ip-alias` - Use modern networking (required for most features)
- `--gateway-api=standard` - Enable the new Gateway API for advanced routing
- `--workload-pool=...` - Enable Workload Identity (secure authentication to Google services)

**This takes 3-5 minutes.** GKE is doing a lot behind the scenes:

- Creating a control plane (managed by Google)
- Provisioning virtual machines for worker nodes
- Installing Kubernetes on each node
- Configuring networking
- Setting up monitoring and logging
- Running health checks

### Step 8: Configure kubectl

Unlike Civo, GKE automatically adds credentials to your kubectl config!

Verify:

```bash
kubectl config get-contexts
```

You should see a context like:

```
gke_kubernetes-course_us-central1-a_kubernetes-course
```

Switch to it (if not already active):

```bash
kubectl config use-context gke_kubernetes-course_us-central1-a_kubernetes-course
```

Check your nodes:

```bash
kubectl get nodes
```

You should see your 2 GKE nodes:

```
NAME                                                STATUS   ROLES    AGE   VERSION
gke-kubernetes-course-default-pool-a1b2c3d4-abcd   Ready    <none>   3m    v1.27.3-gke.100
gke-kubernetes-course-default-pool-a1b2c3d4-efgh   Ready    <none>   3m    v1.27.3-gke.100
```

**Success! You now have a Google Kubernetes Engine cluster!** 🚀

### Step 9: Explore the GKE Dashboard

Head to the [Google Cloud Console](https://console.cloud.google.com/) and navigate to **Kubernetes Engine** (use the search bar at the top).

You'll see your cluster! Click on it to explore:

- **Nodes** - See individual VM details, resource usage
- **Workloads** - View running pods and their status
- **Services & Ingress** - Manage how traffic reaches your apps
- **Configuration** - ConfigMaps, Secrets, and other settings
- **Storage** - Persistent volumes and claims

**The Observability tab** provides:

- Real-time CPU and memory metrics
- Logs from all pods
- Error tracking
- Performance insights

This is one of GKE's killer features—incredible built-in observability!

## Comparing Civo and GKE

You now have experience with two cloud providers. How do they compare?

| Feature                | Civo                     | GKE                                 |
| ---------------------- | ------------------------ | ----------------------------------- |
| **Provisioning speed** | 90-120 seconds ⚡        | 3-5 minutes                         |
| **Ease of setup**      | Very simple 😊           | More complex (but powerful)         |
| **Cost**               | $20-30/month             | $50-70/month                        |
| **Free credit**        | $250 (first month)       | $300 (90 days)                      |
| **Monitoring**         | Basic                    | Advanced (best-in-class)            |
| **Storage options**    | 1 type                   | Multiple types and classes          |
| **Node management**    | Manual                   | Manual or Autopilot (fully managed) |
| **Best for**           | Learning, small projects | Production, enterprise              |
| **Geographic reach**   | Fewer regions            | Global coverage                     |

**Recommendation:**

- **Learning Kubernetes basics?** Civo is perfect—fast, simple, cheap
- **Building production apps?** GKE offers more features and reliability
- **Budget-conscious?** Civo is more affordable long-term
- **Already using Google Cloud?** GKE integrates seamlessly

**You can't go wrong with either!** The skills transfer completely between providers.

## Working with Cloud Load Balancers

One of the big advantages of cloud Kubernetes is **real load balancers**. Let's try it!

### Deploy a Test Application

On either cluster, run:

```bash
kubectl create deployment hello-web --image=gcr.io/google-samples/hello-app:1.0
```

This creates a simple web application.

### Expose it via Load Balancer

```bash
kubectl expose deployment hello-web --type=LoadBalancer --port=80 --target-port=8080
```

**What this does:**

- Creates a Kubernetes **Service** of type LoadBalancer
- The cloud provider provisions an actual load balancer
- Assigns a public IP address
- Routes traffic from that IP to your pods

### Get the Public IP

```bash
kubectl get service hello-web --watch
```

Initially, you'll see `EXTERNAL-IP` showing `<pending>`. After 30-90 seconds, you'll see an actual IP address:

```
NAME        TYPE           CLUSTER-IP    EXTERNAL-IP      PORT(S)
hello-web   LoadBalancer   10.52.4.123   35.192.45.67     80:31234/TCP
```

**Press Ctrl+C to stop watching.**

### Test it!

Open a browser and go to the EXTERNAL-IP (e.g., `http://35.192.45.67`).

You should see:

```
Hello, world!
Version: 1.0.0
Hostname: hello-web-abc123-xyz
```

**You just deployed an application accessible from anywhere on the internet!** 🌍

### Understanding What Happened

Behind the scenes:

1. **You created a Service** of type LoadBalancer
2. **The Cloud Controller Manager** saw this and called the cloud provider API
3. **The cloud provider** provisioned a load balancer in their infrastructure
4. **The load balancer** was configured to route traffic to your cluster nodes
5. **Kube-proxy** on each node routes traffic to the correct pods
6. **You got a public IP** you can use for DNS, sharing, etc.

**This is the magic of managed Kubernetes!** In the bare metal days, setting this up would take hours or days.

### Clean Up the Test

Don't leave this running (it costs money):

```bash
kubectl delete service hello-web
kubectl delete deployment hello-web
```

The load balancer will be automatically deleted by the cloud provider.

## Managing Costs: Avoiding Surprise Bills

Cloud resources cost money. Here's how to avoid unexpected charges:

### 1. **Set Up Billing Alerts**

**For Google Cloud:**

1. Go to **Billing** in the Cloud Console
2. Click **Budgets & alerts**
3. Create a budget (e.g., $50/month)
4. Set up email alerts at 50%, 90%, and 100%

**For Civo:**

1. Check usage in the dashboard regularly
2. They email you when credits are low

### 2. **Delete Clusters When Not Using Them**

Unlike local Kind clusters, cloud clusters cost money even when idle!

**Delete Civo cluster:**

```bash
civo kubernetes delete devops-directive-kubernetes-course
```

**Delete GKE cluster:**

```bash
gcloud container clusters delete kubernetes-course --zone=us-central1-a
```

**Don't worry!** You can recreate them in minutes when you need them again.

### 3. **Delete Associated Resources**

Sometimes deleting the cluster doesn't delete everything. Check for:

**Load balancers:**

```bash
kubectl get services --all-namespaces | grep LoadBalancer
```

Delete any you see.

**Persistent disks (GKE):**

```bash
gcloud compute disks list
```

Delete unused disks.

**Networks (if recreating from scratch):**

```bash
civo network delete devops-directive-kubernetes-course
gcloud compute networks delete kubernetes-course
```

### 4. **Use Autopilot for GKE (Optional)**

GKE Autopilot charges only for the resources your pods actually use, not for entire nodes running 24/7. This can save money for learning projects:

```bash
gcloud container clusters create-auto kubernetes-course-autopilot \
  --region=us-central1
```

## Security Best Practices

### 1. **Limit API Access**

Remember those firewall rules allowing port 6443 from anywhere? For production, restrict it:

```bash
# Only allow from your IP
civo firewall rule create ... --cidr=YOUR_IP_ADDRESS/32
```

### 2. **Use Workload Identity (GKE)**

Instead of downloading and storing Google Cloud credentials, use Workload Identity to let pods authenticate automatically.

The `--workload-pool` flag we used enables this!

### 3. **Enable Network Policies**

Control which pods can talk to each other:

```bash
kubectl apply -f network-policy.yaml
```

### 4. **Regularly Update Clusters**

Kubernetes releases security patches frequently. Keep your cluster updated:

**GKE:** Enable auto-upgrade in cluster settings
**Civo:** Manually upgrade via dashboard or CLI

### 5. **Don't Store Secrets in Git**

Never commit:

- API keys
- Database passwords
- TLS certificates
- Kubeconfig files

Use **Secret Management** tools like Google Secret Manager, HashiCorp Vault, or Sealed Secrets.

## Troubleshooting Common Issues

### Issue: "Permission denied" when creating GKE cluster

**Cause:** Billing not enabled or APIs not activated.

**Solution:**

1. Verify billing is enabled for your project
2. Re-run the API enable command
3. Wait a few minutes and try again

### Issue: Civo cluster creation fails

**Cause:** Could be quota limits or account verification pending.

**Solution:**

1. Check Civo dashboard for error messages
2. Contact Civo support—they're very responsive
3. Verify your account is fully verified

### Issue: Can't access load balancer IP

**Cause:** Firewall rules blocking traffic.

**Solution:**

1. Check firewall rules allow ports 80 and 443
2. Verify the service is actually running: `kubectl get pods`
3. Check service status: `kubectl describe service hello-web`

### Issue: High costs

**Cause:** Left resources running.

**Solution:**

1. List all running clusters
2. Delete unused load balancers
3. Delete unused persistent disks
4. Consider switching to Autopilot (GKE)

## Conclusion

Congratulations! You've leveled up from local Kubernetes to cloud-deployed clusters!

**You've accomplished:**

✅ **Understood managed vs. self-managed Kubernetes**
✅ **Deployed a cluster to Civo** - Fast, simple, beginner-friendly
✅ **Deployed a cluster to Google Kubernetes Engine** - Production-grade, feature-rich
✅ **Configured networking and firewalls** - Learned cloud security basics
✅ **Used real load balancers** - Exposed applications to the internet
✅ **Managed costs** - Learned to avoid surprise bills

**More importantly,** you now have the skills to deploy Kubernetes on any cloud provider. The concepts transfer to AWS EKS, Azure AKS, or any other managed Kubernetes service.

**Key takeaways:**

- **Managed Kubernetes** takes care of the hard parts (control plane, upgrades, etc.)
- **Cloud providers** differ in speed, cost, and features, but the skills are transferable
- **Load balancers** make your apps publicly accessible with minimal effort
- **Cost management** is critical—always clean up unused resources
- **Security** matters—use firewalls, network policies, and workload identity

You're no longer just learning Kubernetes—you're deploying it to production-grade infrastructure! 🚀

## Frequently Asked Questions

### **Q: Which cloud provider should I choose?**

**A:** For learning, **Civo** is great (fast, cheap, simple). For production or if you're already on Google Cloud, **GKE** is excellent. For AWS users, **EKS** is the equivalent. For Azure users, **AKS**. The skills transfer!

### **Q: Can I run the same applications on Civo and GKE?**

**A:** Yes! Standard Kubernetes resources (Deployments, Services, etc.) work identically across providers. Provider-specific features (like Google Cloud integrations) might differ, but core Kubernetes is portable.

### **Q: What happens when my free credits run out?**

**A:** You'll start being charged for resources. Both Google and Civo require explicit action before charging you. Set up billing alerts and delete unused resources before credits expire.

### **Q: Is it safe to learn on cloud clusters?**

**A:** Yes, as long as you follow best practices: use firewalls, don't expose sensitive data, delete resources when done, and set billing alerts. Treat it like learning to drive in a parking lot—safer than a highway, but still requires care.

## Call to Action

**Ready to deploy applications to your cloud cluster?**

👉 Watch the cloud deployment walkthrough: [Civo Setup (36:38-43:02)](https://www.youtube.com/watch?v=2T86xAtR6Fo&t=2198s) | [GKE Setup (43:02-51:44)](https://www.youtube.com/watch?v=2T86xAtR6Fo&t=2582s)

👉 Explore the official documentation: [Civo Docs](https://www.civo.com/docs) | [GKE Docs](https://cloud.google.com/kubernetes-engine/docs)

👉 Next up: Learn about Kubernetes resources (Pods, Deployments, Services) and deploy a real multi-tier application!

**Share your experience:** Which cloud provider did you choose? Any issues you encountered? Drop a comment below!

---

_From local laptop to global cloud—you're officially deploying at scale! Keep building!_ 🌟
---
title: '---'
category: general
tags:
  - general
  - auto-post
description: "publishDate: 2025-10-09T00:00:00Z\ntitle: 'Kubernetes Architecture Explained: Control Plane, Nodes, and How It All Works Together'\nexcerpt: 'Ever won..."
pubDate: '2025-10-09T03:44:35.400Z'
draft: false
excerpt: "publishDate: 2025-10-09T00:00:00Z\ntitle: 'Kubernetes Architecture Explained: Control Plane, Nodes, and How It All Works Together'\nexcerpt: 'Ever won..."
---

publishDate: 2025-10-09T00:00:00Z
title: 'Kubernetes Architecture Explained: Control Plane, Nodes, and How It All Works Together'
excerpt: 'Ever wondered what happens behind the scenes when you deploy an app to Kubernetes? Learn how the control plane, worker nodes, and system components work together—explained in plain English with real-world analogies.'
image: '~/assets/images/default.png'
category: DevOps
tags:
  - kubernetes
  - architecture
  - devops
  - cloud-computing
  - infrastructure
metadata:
  canonical: https://faazabilamri.my.id/kubernetes-architecture-explained
---

## Introduction

Imagine you're trying to understand how a car works. You don't need to be a mechanical engineer to drive one, but understanding the basic components—engine, transmission, wheels, brakes—helps you use it better and fix problems when they arise.

Kubernetes is the same way. You can use it without understanding every detail of its architecture, but knowing how the pieces fit together makes you **significantly more effective**.

In this guide, we'll break down Kubernetes architecture into simple, digestible pieces. No engineering degree required!

By the end of this article, you'll understand:

- The key terms: Cluster, Node, Control Plane, and Data Plane
- What each Kubernetes component does and why it matters
- How these components work together to run your applications
- The standard interfaces (CRI, CNI, CSI) that make Kubernetes flexible

Don't worry—we'll use plenty of real-world analogies to make everything clear.

**Source:** This guide is based on the architecture section of the [Complete Kubernetes Course - From Beginner to Pro](https://www.youtube.com/watch?v=2T86xAtR6Fo&t=749s) by DevOps Directive (timestamp 12:29 - 22:27).

## The Four Foundation Terms You Need to Know

Before we dive into the components, let's establish four critical terms. Understanding these is like learning the difference between a house, room, foundation, and interior—foundational knowledge that makes everything else make sense.

### 1. **Cluster: The Whole System**

A **cluster** is the complete Kubernetes system—all the servers, networking, and resources working together.

**Analogy:** Think of a cluster like an **entire office building**. It has everything needed for the business to operate: offices, meeting rooms, utilities, security, and people.

In Kubernetes terms, the cluster includes:

- All the servers (nodes)
- All the networking
- All the software components
- All your running applications

When someone says "deploy to the Kubernetes cluster," they mean deploy to this entire system.

### 2. **Node: Individual Servers**

A **node** is a single server (physical or virtual machine) within the cluster.

**Analogy:** If the cluster is an office building, a **node is a single floor** in that building. Each floor has its own space and resources, but they all work together as part of the larger building.

**Real-world example:** You might have:

- Node 1: A virtual machine with 8GB RAM, 4 CPUs
- Node 2: A virtual machine with 16GB RAM, 8 CPUs
- Node 3: A virtual machine with 8GB RAM, 4 CPUs

Together, these nodes form your cluster.

### 3. **Control Plane: The Management Layer**

The **control plane** is where all the Kubernetes management components run. It's the "brain" of the system that makes decisions.

**Analogy:** The control plane is like the **executive management floor** in our office building. This is where:

- Strategic decisions are made
- Schedules are created
- Resources are allocated
- Problems are identified and addressed

The control plane **doesn't run your applications**—it manages the system that runs them.

### 4. **Data Plane: Where Applications Run**

The **data plane** (also called worker nodes) is where your actual applications execute.

**Analogy:** The data plane is like the **regular office floors** where employees do their daily work. This is where the actual business happens—people making calls, writing code, serving customers.

In Kubernetes, this is where your containers run and do their actual work.

### Putting It Together

Here's how they relate:

```
Cluster (Office Building)
├── Control Plane (Management Floors)
│   ├── Node 1 (Floor 20 - Executive)
│   ├── Node 2 (Floor 21 - Executive)
│   └── Node 3 (Floor 22 - Executive)
└── Data Plane (Worker Floors)
    ├── Node 4 (Floor 1 - Workers)
    ├── Node 5 (Floor 2 - Workers)
    ├── Node 6 (Floor 3 - Workers)
    └── ...more nodes...
```

**Important note:** In development or small setups, you _can_ run the control plane and data plane on a single node (like a home office), but production systems typically separate them for reliability and security.

## Control Plane Components: The Management Team

Now let's look at the specific components that run on the control plane. These are the pieces that **manage** the cluster.

### 1. **API Server: The Front Desk**

**What it does:** The API Server is the front door to Kubernetes. Every interaction with the cluster goes through here.

**Analogy:** Think of the API Server as the **reception desk** in our office building. Whether you're:

- Requesting information
- Making a delivery
- Asking for changes
- Checking status

...everything goes through reception first.

**In practice:** When you run a command like:

```bash
kubectl get pods
```

Your request goes to the API Server, which handles it and returns the response.

**Why it matters:** This centralized entry point makes Kubernetes secure (one place to control access) and consistent (everyone goes through the same door).

### 2. **etcd: The Filing Cabinet**

**What it does:** etcd is the database that stores all cluster data—what's running, their configurations, their current state, everything.

**Analogy:** etcd is like a **highly secure filing cabinet** that keeps records of everything:

- What applications should be running
- How many copies of each application
- What configurations they need
- The current status of everything

**Important characteristics:**

- **Highly available** - Multiple copies so you never lose data
- **Consistent** - Everyone reading the data sees the same thing
- **Fast** - Optimized for quick reads and writes

**Why it matters:** If etcd loses data, the cluster loses its memory. That's why it's typically run with multiple replicas for safety.

### 3. **Scheduler: The Office Manager**

**What it does:** The Scheduler decides which worker node should run each application.

**Analogy:** Imagine an **office manager** who assigns projects to employees. They consider:

- Who has the right skills (node capabilities)
- Who has available time (free CPU/memory)
- Who's already working on related projects (affinity rules)
- Who shouldn't work together (anti-affinity rules)

**In practice:** When you deploy an application that needs 2GB of RAM and 1 CPU, the Scheduler:

1. Looks at all available nodes
2. Finds nodes with at least 2GB RAM and 1 CPU free
3. Considers other factors (node labels, taints, tolerations)
4. Picks the best node
5. Tells that node to run the application

**Why it matters:** Good scheduling means efficient resource use. Without it, you might fill up one node while others sit empty.

### 4. **Controller Manager: The Supervisor Team**

**What it does:** The Controller Manager runs multiple "controllers"—background processes that watch the cluster and make sure reality matches expectations.

**Analogy:** Think of **department supervisors** who constantly check:

- "Are the right number of people working?" (Replication Controller)
- "Is everyone doing their job?" (Job Controller)
- "Are resources being used properly?" (Resource Quota Controller)

**How it works:** Kubernetes uses a **control loop** pattern:

```
1. Read desired state (what should be happening)
2. Read actual state (what is happening)
3. If they don't match, take action to fix it
4. Wait a bit
5. Repeat from step 1
```

**Example:** You tell Kubernetes "I want 3 copies of my app running."

- The controller sees only 2 are running
- It creates a third copy automatically
- It keeps checking to maintain 3 copies

**Why it matters:** This is what makes Kubernetes "self-healing." Controllers constantly fix problems without human intervention.

### 5. **Cloud Controller Manager: The Facilities Coordinator**

**What it does:** The Cloud Controller Manager handles interactions between Kubernetes and cloud providers (AWS, Google Cloud, Azure, etc.).

**Analogy:** Like a **facilities coordinator** who talks to external vendors:

- Need a new phone line? They call the telecom company.
- Need more office space? They talk to the building owner.

**In practice:** When you need:

- A **load balancer** - It talks to the cloud provider to create one
- **Persistent storage** - It provisions a disk through the cloud API
- **Node management** - It handles adding/removing cloud VMs

**Why it matters:** This abstraction means you can write the same Kubernetes configs and they work across different cloud providers. The Cloud Controller Manager handles the provider-specific details.

## Data Plane Components: Where Work Gets Done

Now let's look at what runs on worker nodes—where your applications actually execute.

### 1. **Kubelet: The Floor Manager**

**What it does:** Kubelet is an agent that runs on every worker node and manages containers on that node.

**Analogy:** The **floor manager** in our office building who:

- Receives instructions from management
- Makes sure workers show up and do their jobs
- Reports status back to management
- Handles local problems

**In practice:** The Kubelet:

1. Receives instructions from the API Server ("run this container")
2. Tells the container runtime to start the container
3. Monitors the container's health
4. Reports status back to the API Server
5. Restarts containers if they crash

**Why it matters:** The Kubelet is the "boots on the ground"—it's what actually makes things happen on each node.

### 2. **Kube-proxy: The Phone System**

**What it does:** Kube-proxy manages networking rules so containers can communicate with each other and the outside world.

**Analogy:** Like the **phone system** in our office building that routes calls:

- Internal calls between employees
- External calls to customers
- Conference calls between departments

**In practice:** Kube-proxy sets up networking rules (usually using iptables) so that:

- Containers can find each other by name
- Traffic gets distributed across multiple copies of an application
- External traffic reaches the right containers

**Important note:** Some newer networking solutions (like Cilium) don't use kube-proxy, instead using more advanced kernel features like eBPF. But most clusters still use kube-proxy.

**Why it matters:** Without kube-proxy, your containers couldn't communicate properly. It's essential for service discovery and load balancing.

### 3. **Container Runtime: The Actual Worker**

**What it does:** The container runtime is the software that actually runs containers (Docker, containerd, CRI-O, etc.).

**Analogy:** The **employees themselves** doing the actual work, versus managers who coordinate them.

**In practice:** When Kubelet says "run this container," the container runtime:

1. Pulls the container image
2. Creates the container
3. Starts the container process
4. Monitors the process

**Historical note:** Kubernetes used to support Docker directly, but as of Kubernetes 1.20, it only supports container runtimes that implement the **Container Runtime Interface (CRI)**. More on that next!

## The Three Standard Interfaces: Making Kubernetes Modular

One of Kubernetes' strengths is its **modularity**. Rather than hardcoding how to run containers, handle networking, or manage storage, Kubernetes defines standard **interfaces** that different implementations can plug into.

Think of it like outlets in your home—the outlet is standardized, so any device that has the right plug will work, regardless of manufacturer.

### 1. **CRI: Container Runtime Interface**

**What it is:** A standard way for Kubernetes to tell container runtimes "run this container" without caring about the specific runtime.

**Available options:**

- **containerd** - Most popular, lightweight, industry standard
- **CRI-O** - Designed specifically for Kubernetes
- **Docker** (via cri-dockerd adapter) - Legacy option

**Why it matters:** You can swap container runtimes without changing your applications. If a new, faster runtime comes along, you can switch to it easily.

**Analogy:** Like having a standard car ignition—whether you drive a Toyota, Ford, or BMW, you turn the key the same way.

### 2. **CNI: Container Network Interface**

**What it is:** A standard way to set up networking for containers.

**Available options:**

- **Calico** - Popular, feature-rich, great for complex networking
- **Flannel** - Simple, easy to set up
- **Cilium** - Modern, uses eBPF for high performance
- **Weave** - Easy setup, good for small clusters
- **Cloud provider CNIs** - AWS VPC CNI, Azure CNI, Google Cloud CNI

**Why it matters:** Different CNIs offer different features:

- Some are faster
- Some have better security (network policies)
- Some integrate better with cloud providers

**Analogy:** Like different phone systems—they all let people talk to each other, but some have better call quality, conference features, or international rates.

### 3. **CSI: Container Storage Interface**

**What it is:** A standard way to provide storage to containers.

**Available options:**

- **Cloud provider disks** - AWS EBS, Google Persistent Disk, Azure Disk
- **Network storage** - NFS, Ceph, GlusterFS
- **Local storage** - Using disks directly on nodes
- **Special purpose** - Cert-manager CSI (for TLS certificates), Secrets Store CSI (for secrets)

**Why it matters:** Storage is critical for databases and stateful applications. CSI lets you:

- Automatically provision storage
- Snapshot data for backups
- Resize volumes
- Move data between nodes

**Analogy:** Like different types of filing systems in an office—file cabinets, cloud storage, secure safes. They all store things, but some are better for specific use cases.

## How It All Works Together: A Real Example

Let's walk through what happens when you deploy an application to Kubernetes:

### Step 1: You Submit a Request

You run: `kubectl create deployment my-app --image=my-app:v1.0`

This request goes to the **API Server**.

### Step 2: API Server Saves the Intent

The API Server:

- Validates your request
- Stores it in **etcd** (the database)
- Returns "success" to you

At this point, nothing is running yet! You've just declared your _intent_.

### Step 3: Controller Manager Notices

The **Deployment Controller** (part of Controller Manager):

- Sees the new deployment in etcd
- Creates a **ReplicaSet** to manage the app copies
- The **ReplicaSet Controller** creates **Pod** specifications

### Step 4: Scheduler Assigns Nodes

The **Scheduler**:

- Notices the new Pods that need to run
- Checks which nodes have enough resources
- Picks the best node for each Pod
- Updates etcd with the node assignments

### Step 5: Kubelet Starts Containers

The **Kubelet** on the selected node:

- Sees that a new Pod is assigned to it
- Tells the **container runtime** to pull the image
- Starts the container
- Begins health checks
- Reports status back to API Server

### Step 6: Kube-proxy Sets Up Networking

**Kube-proxy**:

- Notices the new Pod
- Updates networking rules
- Ensures the Pod can communicate

### Step 7: Continuous Monitoring

The **Controller Manager** continuously:

- Checks if the right number of Pods are running
- Restarts failed Pods
- Maintains desired state

All of this happens **automatically** in seconds after your single command!

## Production vs. Development Clusters

It's important to understand that cluster architecture varies based on use case:

### Development/Learning Cluster

- **Single node** - Everything runs on one machine
- **Minimal resources** - 2-4GB RAM might be enough
- **Example:** Kind, Minikube, Docker Desktop Kubernetes

**Good for:** Learning, testing, local development

### Production Cluster

- **Multiple control plane nodes** - Usually 3 or 5 for high availability
- **Many worker nodes** - As many as needed for your workloads
- **Separated** - Control plane and data plane on different nodes
- **Examples:** Google Kubernetes Engine, Amazon EKS, Azure AKS

**Good for:** Running real applications, serving users

## The Beauty of Abstraction

Here's what's amazing about Kubernetes architecture:

**As a user, you mostly interact with the API Server.** You don't need to know:

- Which controller will handle your request
- How the Scheduler makes decisions
- Which container runtime is being used
- What CNI plugin is handling networking

You just say "I want this" and Kubernetes figures out the "how."

This **abstraction** is what makes Kubernetes so powerful—and why understanding the architecture helps you work more effectively, even though you don't interact with most components directly.

## Conclusion

Kubernetes architecture might seem complex at first, but break it down and it's quite logical:

**Control Plane = The Management Team**

- API Server: The front desk
- etcd: The filing cabinet
- Scheduler: The office manager
- Controller Manager: The supervisors
- Cloud Controller Manager: The facilities coordinator

**Data Plane = Where Work Happens**

- Kubelet: The floor manager
- Kube-proxy: The phone system
- Container Runtime: The actual workers

**Standard Interfaces = Plug-and-Play Flexibility**

- CRI: How to run containers
- CNI: How to handle networking
- CSI: How to manage storage

Together, these components create a self-managing system that runs your applications reliably at any scale.

**Remember:** You don't need to be an expert in every component to use Kubernetes effectively. But understanding the architecture helps you:

- Debug problems when they occur
- Make informed decisions about configurations
- Communicate effectively with your team
- Appreciate why Kubernetes works the way it does

## Frequently Asked Questions

### **Q: Do I need to install and configure all these components myself?**

**A:** Not usually! If you use a managed Kubernetes service (Google GKE, Amazon EKS, Azure AKS, Civo, etc.), the cloud provider handles the control plane for you. You just use it. Even for self-hosted clusters, tools like kubeadm, k3s, or Rancher automate most of the setup.

### **Q: What happens if a control plane component fails?**

**A:** In production clusters, control plane components typically run with multiple replicas (usually 3 or 5). If one fails, others continue working. This is called "high availability." Your applications keep running even if control plane components temporarily fail—you just can't make changes until they're restored.

### **Q: Can I mix different CNI or CSI providers in the same cluster?**

**A:** You typically use one CNI for the entire cluster (consistency in networking is important). However, you can use multiple CSI providers simultaneously—for example, local storage for some workloads and cloud storage for others.

### **Q: How much do I need to know about the container runtime (CRI)?**

**A:** Not much! For most use cases, you'll never directly interact with it. Kubelet handles the interaction. You just need to know it exists and that your cluster uses one of the standard options (containerd, CRI-O, etc.).

## Call to Action

**Ready to see this architecture in action?**

👉 Watch the detailed architecture walkthrough: [Kubernetes Course (12:29 - 22:27)](https://www.youtube.com/watch?v=2T86xAtR6Fo&t=749s)

👉 Next step: Learn how to set up your first cluster and interact with these components hands-on!

👉 Explore the [official Kubernetes architecture documentation](https://kubernetes.io/docs/concepts/architecture/) for even more technical details

**Share your learning:** What component surprised you most? What analogy helped you understand? Drop a comment below!

---

_Understanding the architecture is like knowing how the engine works—you'll be a much more confident driver. Keep learning!_ 🚀